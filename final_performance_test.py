#!/usr/bin/env python3
"""
Final performance validation test.
"""

import asyncio
import time
import statistics
from profile_server_workflow import test_server_workflow

async def run_performance_tests():
    """Run multiple performance tests to get accurate statistics"""
    
    print("ğŸ§ª FINAL PERFORMANCE VALIDATION")
    print("=" * 70)
    print("ğŸ¯ Testing optimized streaming performance...")
    
    times = []
    chunks = []
    
    for i in range(5):
        print(f"\nğŸ”„ Test run {i+1}/5:")
        
        start_time = time.perf_counter()
        result = await test_server_workflow()
        end_time = time.perf_counter()
        
        total_time = end_time - start_time
        times.append(total_time)
        
        if result.get("success"):
            chunk_count = result.get("content_chunks", 0)
            chunks.append(chunk_count)
            print(f"   âœ… {total_time:.3f}s, {chunk_count} chunks")
        else:
            print(f"   âŒ Failed: {result.get('error', 'Unknown error')}")
        
        # Wait between tests
        if i < 4:
            await asyncio.sleep(1)
    
    # Calculate statistics
    if times:
        avg_time = statistics.mean(times)
        min_time = min(times)
        max_time = max(times)
        
        print(f"\nğŸ“Š PERFORMANCE STATISTICS")
        print("=" * 70)
        print(f"â±ï¸  Average time: {avg_time:.3f}s")
        print(f"â±ï¸  Best time:    {min_time:.3f}s")
        print(f"â±ï¸  Worst time:   {max_time:.3f}s")
        
        if chunks:
            avg_chunks = statistics.mean(chunks)
            throughput = avg_chunks / avg_time if avg_time > 0 else 0
            print(f"ğŸ“¦ Average chunks: {avg_chunks:.1f}")
            print(f"ğŸš€ Avg throughput: {throughput:.1f} chunks/s")
        
        # Compare with baseline
        baseline_time = 24.0  # Original unoptimized time
        improvement = baseline_time / avg_time
        
        print(f"\nğŸ‰ OPTIMIZATION RESULTS")
        print("=" * 70)
        print(f"ğŸ“ˆ Performance improvement: {improvement:.1f}x faster")
        print(f"âš¡ Time saved per request: {baseline_time - avg_time:.1f}s")
        print(f"ğŸ“‰ Response time: {baseline_time:.1f}s â†’ {avg_time:.3f}s")
        
        # Calculate potential cost savings
        if improvement > 10:
            print(f"\nğŸ’° IMPACT ANALYSIS")
            print("-" * 40)
            print(f"ğŸ”¥ MASSIVE performance gain: {improvement:.0f}x faster!")
            print(f"âš¡ Eliminated OpenAI SDK Pydantic overhead")
            print(f"ğŸš€ Raw HTTP streaming approach successful")
            print(f"ğŸ’ Production-ready optimization")

async def main():
    await run_performance_tests()

if __name__ == "__main__":
    asyncio.run(main())