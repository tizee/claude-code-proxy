# Anthropic API Proxy for Claude Code üîÑ

[![GitHub latest commit](https://img.shields.io/github/last-commit/tizee/anthropic-proxy)](https://github.com/tizee/anthropic-proxy)
[![License](https://img.shields.io/github/license/tizee/anthropic-proxy)](https://github.com/tizee/anthropic-proxy/blob/main/LICENSE)

A proxy server that enables Claude Code to work with multiple model providers through two modes:

1. **OpenAI-Compatible Mode**: Translates Anthropic API requests to OpenAI-compatible endpoints
2. **Direct Claude API Mode**: Routes requests directly to official Claude API or compatible endpoints

This allows you to use Claude Code with both OpenAI-compatible models and native Claude API endpoints. For third-party models to support Claude Code image files (URL/base64), they must natively support multimodal image understanding.

## Primary Use Case: Claude Code Proxy

The main purpose of this project is to serve as a proxy for **Claude Code**, enabling it to connect to and utilize third-party models that follow the OpenAI API format. This extends the power of Claude Code beyond its native models.

### Recommended Usage Strategy

**1. Primary Choice: Official Claude Models**

If you have a Claude Pro subscription or API access, it is highly recommended to use the official Anthropic models as your default choice. This ensures the best performance, latest features, and full compatibility.

**2. Fallback/Alternative: This Proxy**

Use this proxy in the following scenarios:
- When your official Claude API quota has been exhausted.
- As a cost-effective alternative for less critical tasks.
- To experiment with different models while maintaining the Claude Code workflow.

## Supported Claude Code Versions

| Version | Status | Notes |
|---------|--------|-------|
| 1.0.51 | ‚úÖ Tested | Current supported version |
| 1.0.x   | ‚ö†Ô∏è Likely Compatible | Earlier versions may work but are untested |

## Tested Models

### OpenAI-Compatible Mode
| Provider | Model | Format | Status | Notes |
|----------|-------|--------|--------|-------|
| **DeepSeek** | deepseek-v3 | OpenAI | ‚úÖ Fully Tested | Recommended for background tasks |
| **DeepSeek** | deepseek-r1 | OpenAI | ‚úÖ Fully Tested | Optimized for thinking/reasoning |
| **OpenRouter** | claude models | OpenAI | ‚úÖ Fully Tested | Claude via OpenAI format |
| **ByteDance** | doubao-seed-1.6 | OpenAI | ‚úÖ Fully Tested | Doubao model support |
| **OpenRouter** | Gemini-2.5-pro | OpenAI | ‚úÖ Fully Tested | Google Gemini via OpenRouter |
| **OpenRouter** | gemini-2.5-flash-lite-preview-06-17 | OpenAI | ‚úÖ Fully Tested | Gemini preview via OpenRouter |

### Direct Claude API Mode
| Provider | Model | Format | Status | Notes |
|----------|-------|--------|--------|-------|
| **Anthropic** | claude-3-5-sonnet-20241022 | Direct | ‚úÖ Fully Tested | Official Claude API |
| **Anthropic** | claude-3-5-haiku-20241022 | Direct | ‚úÖ Fully Tested | Official Claude API |
| **Anthropic** | claude-3-opus-20240229 | Direct | ‚úÖ Fully Tested | Official Claude API |

## Known Issues

### Provider-Specific Issues

**‚ö†Ô∏è Groq Provider - Tool Call Limitations (as of January 2025)**

The Groq provider has known issues with tool call functionality:
- **Multiple tool calls fail**: When Claude Code requests multiple tools in a single interaction, Groq may not handle them correctly
- **Tool call generation instability**: Even single tool calls may fail intermittently
- **Confirmed across implementations**: This issue affects both JavaScript and Python implementations, confirming it's a provider-side problem

**Root Cause**: This is acknowledged by the Kimi model team on Twitter, where they mentioned bugs in the Kimi-K2-Instruct model's tool call handling, specifically for multi-turn tool calls.

**Workaround**: Use alternative providers like:
- **Moonshot AI** (kimi-k2-0711-preview via direct API)
- **Google Gemini** (via OpenRouter)
- **DeepSeek** models
- **OpenRouter** with other models

**Future**: This issue may be resolved by Groq in future updates, but currently requires using alternative providers for reliable tool call functionality.

## Key Features

### üîÑ Dual-Mode Operation
- **OpenAI-Compatible Mode**: Convert Anthropic API requests to OpenAI format for third-party providers
- **Direct Claude API Mode**: Route requests directly to official Anthropic API with native format preservation

### üß† Intelligent Routing
- Automatic model selection based on request characteristics (token count, thinking mode, etc.)
- Configurable fallback to long-context models when token limits are exceeded
- Support for both direct and OpenAI-compatible models in routing configuration

### üîß Enhanced Error Handling
- Structured error parsing for both OpenAI and Claude API responses
- Detailed logging and debugging information for API failures
- Graceful handling of connection timeouts and rate limits
- Enhanced client reliability with automatic retry mechanisms. Configure via `MAX_RETRIES` environment variable (default: 2 retries)

### üìä Advanced Features
- Streaming support for both modes with proper error handling
- Token counting and usage statistics tracking
- Custom model configuration with per-model settings
- Support for thinking mode and reasoning effort parameters

## Quick Start

### Prerequisites
- Python 3.9+
- [uv](https://github.com/astral-sh/uv) (recommended)
- [make](https://www.gnu.org/software/make/) (optional but recommended)
- API keys for desired providers

### Installation

#### Option 1: Global Installation (Recommended)
Install once and use from any directory:

```bash
git clone https://github.com/tizee/claude-code-proxy.git
cd claude-code-proxy
./install.sh
```

After installation, you can run the proxy from anywhere:
```bash
claude-proxy        # Production mode
claude-proxy -d     # Development mode
claude-proxy -p 8080  # Custom port
```

#### Option 2: Local Installation
Traditional local installation:

```bash
git clone https://github.com/tizee/claude-code-proxy.git
cd claude-code-proxy
uv install
```

### Configuration
1. Copy `.env.example` to `.env`
2. Set your API keys for the desired providers
3. Configure models in `models.yaml` with appropriate mode settings

#### Direct Claude API Mode Configuration
To use official Claude API or compatible endpoints directly:

```yaml
models:
  claude-3-5-sonnet-direct:
    model_name: claude-3-5-sonnet-20241022
    api_base: https://api.anthropic.com
    api_key_name: ANTHROPIC_API_KEY
    direct: true  # Enable direct Claude API mode
    max_tokens: 8k   # Supports shorthand: 8k, 16k, 32k, etc.
    max_input_tokens: 200k
```

#### OpenAI-Compatible Mode Configuration
For OpenAI-compatible endpoints:

```yaml
models:
  deepseek-v3:
    model_name: deepseek-chat
    api_base: https://api.deepseek.com/v1
    api_key_name: DEEPSEEK_API_KEY
    direct: false  # Use OpenAI-compatible mode (default)
    max_tokens: 8k   # Supports shorthand notation
    max_input_tokens: 128k
```

**Note**: Token limits support both numeric values (e.g., `8192`) and shorthand notation (e.g., `8k`, `16K`, `32k`, `128K`, `200k`). The shorthand format is case-insensitive.

### Running the Server
```bash
make run
```
To run in development mode with auto-reload:
```bash
make dev
```

### Connecting Claude Code
```bash
ANTHROPIC_BASE_URL=http://localhost:8082 claude
```

## Development

For detailed information on the architecture, features, and testing of this project, please refer to the documents in the `docs/` directory:

- **[Architecture](./docs/architecture.md)**: A high-level overview of the proxy's architecture.
- **[Features](./docs/features.md)**: A description of the key features of the proxy.
- **[Testing](./docs/testing.md)**: Instructions on how to run the unit and performance tests.

Additionally, the `CLAUDE.md` file provides guidance for both developers and AI assistants working with this project:

- **For Developers**: Helps understand the codebase structure, design patterns, and key commands.
- **For AI Assistants**: Contains specific instructions to help AI tools effectively navigate and modify the codebase.

Reading both the documentation in `docs/` and `CLAUDE.md` will give you a comprehensive understanding of the project.

## Scripts

This repository includes convenient installation and management scripts:

- **`./install.sh`**: Installs the proxy globally so you can run `claude-proxy` from any directory
- **`./uninstall.sh`**: Removes the global installation
- **`claude-proxy`**: Global command after installation (see [Installation](#installation))

Example usage:
```bash
# Installation
./install.sh

# Usage
claude-proxy -d    # Development mode
claude-proxy --help

# Removal
./uninstall.sh
```

## Credit & Acknowledgment

This project is forked from and based on [claude-code-proxy](https://github.com/1rgs/claude-code-proxy) by [@1rgs](https://github.com/1rgs). The intelligent routing feature was inspired by [claude-code-router](https://github.com/musistudio/claude-code-router).
